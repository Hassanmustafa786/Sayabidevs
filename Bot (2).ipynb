{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a77c731",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddc4498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "\n",
    "import bs4 as bs\n",
    "import requests\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b10cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_wikipedia(topic):\n",
    "    url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{topic}\"\n",
    "    response = requests.get(url)\n",
    "    data = json.loads(response.text)\n",
    "    \n",
    "    # Extract the relevant information\n",
    "    summary = data[\"extract\"]\n",
    "    return summary.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd9e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = input(\"Enter a topic to scrape: \")\n",
    "summary = scrape_wikipedia(topic)\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd07cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"summary\":summary}]\n",
    "df = pd.DataFrame(data, columns=[\"summary\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0150153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = re.sub(r'\\[[0-9]*\\]', ' ', str(df))\n",
    "df = re.sub(r'\\s+', ' ', str(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences = nltk.sent_tokenize(df)\n",
    "df_words = nltk.word_tokenize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc98398",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnlemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def perform_lemmatization(tokens):\n",
    "    return [wnlemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
    "\n",
    "def get_processed_text(document):\n",
    "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210209b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "greeting_inputs = (\"hey\", \"good morning\", \"good evening\", \"morning\", \"evening\", \"hi\", \"whatsup buddy\",\"good night\",\"I'm also good\")\n",
    "greeting_responses = [\"hey\", \"hey, how are you?\", \"Yo Bro\", \"hello, how you doing\", \"hello\", \"Welcome, I am good and you\"]\n",
    "\n",
    "def generate_greeting_response(greeting):\n",
    "    for token in greeting.split():\n",
    "        if token.lower() in greeting_inputs:\n",
    "            return random.choice(greeting_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681f93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81320b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(user_input):\n",
    "    bot_response = ''\n",
    "    df_sentences.append(user_input)\n",
    "\n",
    "    word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words='english')\n",
    "    all_word_vectors = word_vectorizer.fit_transform(df_sentences)\n",
    "    similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)\n",
    "    similar_sentence_number = similar_vector_values.argsort()[0][-2]\n",
    "\n",
    "    matched_vector = similar_vector_values.flatten()\n",
    "    matched_vector.sort()\n",
    "    vector_matched = matched_vector[-2]\n",
    "\n",
    "    if vector_matched == 0:\n",
    "        bot_response = bot_response + \"I am sorry, I could not understand you\"\n",
    "        return bot_response\n",
    "    else:\n",
    "        bot_response = bot_response + df_sentences[similar_sentence_number]\n",
    "        return bot_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fec39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectorizer = TfidfVectorizer(tokenizer=get_processed_text, stop_words='english')\n",
    "all_word_vectors = word_vectorizer.fit_transform(df_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe16074",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_vector_values = cosine_similarity(all_word_vectors[-1], all_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_sentence_number = similar_vector_values.argsort()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d03010",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_dialogue = True\n",
    "print(\"Hello, I am your Bot. You can ask me any question. And if you want to quit just type bye\")\n",
    "while(continue_dialogue == True):\n",
    "    human_text = input()\n",
    "    human_text = human_text.lower()\n",
    "    if human_text != 'bye':\n",
    "        if human_text == 'thanks' or human_text == 'thank you very much' or human_text == 'thank you':\n",
    "            continue_dialogue = False\n",
    "            print(\"Bot: Most welcome\")\n",
    "        else:\n",
    "            if generate_greeting_response(human_text) != None:\n",
    "                print(\"Bot: \" + generate_greeting_response(human_text))\n",
    "            else:\n",
    "                print(\"Bot: \", end=\"\")\n",
    "                print(scrape_wikipedia(human_text))\n",
    "    else:\n",
    "        continue_dialogue = False\n",
    "        print(\"Bot: Good bye and take care of yourself...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6c0720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
